{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43m3omfZDrQq"
      },
      "outputs": [],
      "source": [
        "pip install scalecast --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6nSG3mdECLS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from scalecast.Forecaster import Forecaster\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset and quick check\n",
        "df = pd.read_excel('time_series_north_extent.xlsx')\n",
        "df.index = pd.to_datetime(df['DATE'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b3p_jrZEO2w"
      },
      "outputs": [],
      "source": [
        "# Call the Forecaster object with the y and current_dates parameters specified\n",
        "f = Forecaster(\n",
        "y=df['extent'],\n",
        "current_dates=df['DATE'])\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfHyTSKE7rku"
      },
      "outputs": [],
      "source": [
        "# Training and Test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_lstm, val_lstm = train_test_split(df, test_size=0.2,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh_2rIcyN1p9"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 6\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "f.set_test_length(len(val_lstm))       # 1. Observations to test the results\n",
        "f.generate_future_dates(len(val_lstm)) # 2. Future points to forecast\n",
        "f.set_estimator('lstm')                # 3. LSTM neural network\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test6',\n",
        "    lags=20,\n",
        "    batch_size=12,\n",
        "    epochs=22,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(60,),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwHmprLuO--K"
      },
      "outputs": [],
      "source": [
        "# Display Model summaries with their metrics\n",
        "\n",
        "f.export('model_summaries',determine_best_by='TestSetMAE')[\n",
        "    ['ModelNickname',\n",
        "     'TestSetMAPE',\n",
        "     'TestSetRMSE',\n",
        "     'TestSetR2',\n",
        "     'TestSetMAE',\n",
        "     'best_model']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCU9guUaESIQ"
      },
      "outputs": [],
      "source": [
        "# PACF (Partial Auto Correlation Function) plot, which measures how much the y variable, in our case, ice extent, \n",
        "# is correlated to past values of itself and how far back a statistically significant correlation exists. \n",
        "\n",
        "f.plot_pacf(lags=26)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDvgdNi3EhJI"
      },
      "outputs": [],
      "source": [
        "# Decompose the series into its trend, seasonal, and residual parts\n",
        "\n",
        "f.seasonal_decompose().plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsjrcFZxEkU3"
      },
      "outputs": [],
      "source": [
        "# seriesâ€™ stationarity, p value is not less than 0.05 and thus it is stationary\n",
        "stat, pval, _, _, _, _ = f.adf_test(full_res=True)\n",
        "print(\"stat: %s\" %stat)\n",
        "print(\"pval: %s\" %pval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jklX6KXSEuCO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "f.set_test_length(len(val_lstm))       # 1. Observations to test the results\n",
        "f.generate_future_dates(len(val_lstm)) # 2. Future points to forecast\n",
        "f.set_estimator('lstm')                # 3. LSTM neural network\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test1',\n",
        "    lags=36,\n",
        "    batch_size=32,\n",
        "    epochs=20,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(32,32),\n",
        "    dropout=(0,0),\n",
        "    plot_loss=True\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r2uJhtkFoia"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 2\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test2',\n",
        "    lags=24,\n",
        "    batch_size=16,\n",
        "    epochs=50,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(16,),\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc8NA9xaF8Wv"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 3\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test3',\n",
        "    lags=48,\n",
        "    batch_size=24,\n",
        "    epochs=45,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(24,),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyvAlii3GNaX"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 4\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test4',\n",
        "    lags=16,\n",
        "    batch_size=12,\n",
        "    epochs=15,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(64,),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpZ2wZYyM8kG"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 5\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test5',\n",
        "    lags=28,\n",
        "    batch_size=28,\n",
        "    epochs=12,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(128,),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbq127NDOkar"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 7\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test7',\n",
        "    lags=16,\n",
        "    batch_size=12,\n",
        "    epochs=15,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(64,),\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5cK0rR6QU-p"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 8\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test8',\n",
        "    lags=16,\n",
        "    batch_size=12,\n",
        "    epochs=15,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.1,\n",
        "    lstm_layer_sizes=(128,),\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTknYs-ZQz0n"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 9\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test9',\n",
        "    lags=30,\n",
        "    batch_size=12,\n",
        "    epochs=20,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.0001,\n",
        "    lstm_layer_sizes=(64,),\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bdgw5bjROgJ"
      },
      "outputs": [],
      "source": [
        "# Looking for the best model test 10\n",
        "\n",
        "f.manual_forecast(\n",
        "    call_me='lstm_test10',\n",
        "    lags=16,\n",
        "    batch_size=12,\n",
        "    epochs=100,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.0001,\n",
        "    lstm_layer_sizes=(64,),\n",
        "    callbacks=EarlyStopping(\n",
        "        monitor='val_loss',               \n",
        "        patience=5,\n",
        "    ),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "zd2Ofohbl0_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from scalecast.Forecaster import Forecaster\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load dataset\n",
        "df_norm = pd.read_excel('time_series_north_extent.xlsx')\n",
        "\n",
        "# Normalize data\n",
        "data_norm = df_norm['extent'].values.reshape(-1,1)\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform data using the scaler\n",
        "normalized_data = scaler.fit_transform(data_norm)\n",
        "normalized_data_df = pd.DataFrame(normalized_data,columns=['extent'])\n",
        "df_norm['extent'] = normalized_data_df['extent']\n",
        "\n",
        "# Set Inde to datetiem\n",
        "df_norm.index = pd.to_datetime(df_norm['DATE'])\n",
        "\n",
        "# Call the Forecaster object with the y and current_dates parameters specified\n",
        "f_norm = Forecaster(\n",
        "y=df_norm['extent'],\n",
        "current_dates=df_norm['DATE'])\n",
        "\n",
        "# Training and Test datasets\n",
        "train_lstm_norm, val_lstm_norm = train_test_split(df_norm, test_size=0.2,\n",
        "                                                  shuffle=False)\n",
        "# Looking for the best model test 6\n",
        "f_norm.set_test_length(len(val_lstm_norm))       \n",
        "f_norm.generate_future_dates(len(val_lstm_norm))\n",
        "f_norm.set_estimator('lstm')    \n",
        "f_norm.manual_forecast(\n",
        "    call_me='lstm_test6_norm',\n",
        "    lags=20,\n",
        "    batch_size=12,\n",
        "    epochs=22,\n",
        "    validation_split=.2,\n",
        "    shuffle=True,\n",
        "    activation='tanh',\n",
        "    optimizer='Adam',\n",
        "    learning_rate=0.001,\n",
        "    lstm_layer_sizes=(60,),\n",
        "    dropout=(0,),\n",
        "    plot_loss=True,\n",
        ")\n",
        "f_norm.plot_test_set(order_by='TestSetMAE',models='top_3',ci=True)\n",
        "\n",
        "# Model summaries\n",
        "f_norm.export('model_summaries',determine_best_by='TestSetMAE')[\n",
        "    ['ModelNickname', 'TestSetMAPE','TestSetRMSE', 'TestSetR2',\n",
        "     'TestSetMAE','best_model']]"
      ],
      "metadata": {
        "id": "Mfmu8Y1bl429"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_norm.export('model_summaries',determine_best_by='TestSetMAE')[\n",
        "    ['ModelNickname',\n",
        "     'TestSetMAPE',\n",
        "     'TestSetRMSE',\n",
        "     'TestSetR2',\n",
        "     'TestSetMAE',\n",
        "     'best_model']\n",
        "]"
      ],
      "metadata": {
        "id": "7g2QJlk9qTrk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}